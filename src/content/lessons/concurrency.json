{
    "title": "Concurrency",
    "lessons": [
      {
        "title": "Introduction to Concurrency",
        "content": [
          {
            "type": "paragraph",
            "text": "Concurrency refers to the ability of a system to execute multiple tasks or processes at the same time. In programming, concurrency can be achieved through threads, processes, or asynchronous programming."
          },
          {
            "type": "bullets",
            "items": [
              "Concurrency allows tasks to make progress simultaneously, improving performance and responsiveness.",
              "It can involve managing multiple threads or processes in parallel or overlapping the execution of tasks.",
              "Proper handling of concurrency is critical for ensuring data consistency and preventing race conditions."
            ]
          }
        ]
      },
      {
        "title": "Threads vs Processes",
        "content": [
          {
            "type": "paragraph",
            "text": "A thread is the smallest unit of execution in a process. A process can have multiple threads running concurrently, sharing the same memory space. A process, on the other hand, is a separate program with its own memory space."
          },
          {
            "type": "bullets",
            "items": [
              "Threads: Lighter, share memory, and can communicate directly, but need synchronization.",
              "Processes: Heavier, have separate memory spaces, and communicate via inter-process communication (IPC)."
            ]
          },
          {
            "type": "code",
            "language": "python",
            "code": "import threading\n\ndef print_hello():\n    print('Hello from thread')\n\nthread = threading.Thread(target=print_hello)\nthread.start()\nthread.join()"
          },
          {
            "type": "paragraph",
            "text": "In this example, a new thread is started to run the `print_hello` function concurrently with the main program."
          }
        ]
      },
      {
        "title": "Common Problems in Concurrency",
        "content": [
          {
            "type": "paragraph",
            "text": "Concurrency can introduce several common problems, such as race conditions, deadlocks, and livelocks."
          },
          {
            "type": "bullets",
            "items": [
              "Race Condition: Occurs when two or more threads or processes access shared resources simultaneously, leading to unpredictable behavior.",
              "Deadlock: Happens when two or more threads or processes are blocked, each waiting for the other to release a resource.",
              "Livelock: Similar to a deadlock, but instead of blocking, threads or processes keep changing state without making progress."
            ]
          }
        ]
      },
      {
        "title": "Locks and Synchronization",
        "content": [
          {
            "type": "paragraph",
            "text": "Locks are used to synchronize access to shared resources, ensuring that only one thread or process can access a critical section of code at a time."
          },
          {
            "type": "bullets",
            "items": [
              "Mutex (Mutual Exclusion): Ensures that only one thread can access a resource at a time.",
              "Semaphores: Generalize mutexes to allow multiple threads to access a resource but limit the number of concurrent accesses.",
              "Condition Variables: Allow threads to wait for certain conditions to be met before proceeding."
            ]
          },
          {
            "type": "code",
            "language": "python",
            "code": "import threading\n\nlock = threading.Lock()\n\ncounter = 0\n\ndef increment():\n    global counter\n    with lock:\n        for _ in range(1000):\n            counter += 1\n\nthreads = [threading.Thread(target=increment) for _ in range(10)]\nfor t in threads:\n    t.start()\nfor t in threads:\n    t.join()\nprint(counter)  # Output should be 10000"
          },
          {
            "type": "paragraph",
            "text": "In this example, the `Lock` is used to synchronize access to the shared variable `counter`, ensuring correct increments without race conditions."
          }
        ]
      },
      {
        "title": "Deadlock Prevention",
        "content": [
          {
            "type": "paragraph",
            "text": "Deadlock occurs when threads or processes wait indefinitely for resources held by each other. Deadlock prevention techniques include acquiring locks in a fixed order and using timeouts to detect and resolve deadlocks."
          },
          {
            "type": "code",
            "language": "python",
            "code": "import threading\nimport time\n\ndef thread1(lock1, lock2):\n    with lock1:\n        time.sleep(1)\n        with lock2:\n            print('Thread 1 finished')\n\ndef thread2(lock1, lock2):\n    with lock2:\n        time.sleep(1)\n        with lock1:\n            print('Thread 2 finished')\n\nlock1 = threading.Lock()\nlock2 = threading.Lock()\nt1 = threading.Thread(target=thread1, args=(lock1, lock2))\nt2 = threading.Thread(target=thread2, args=(lock1, lock2))\nt1.start()\nt2.start()\nt1.join()\nt2.join()"
          },
          {
            "type": "paragraph",
            "text": "In this scenario, if locks are not acquired in a consistent order, it could result in a deadlock, as both threads wait for each other. Preventing deadlocks requires careful handling of lock acquisition."
          }
        ]
      },
      {
        "title": "Thread Pools and Task Scheduling",
        "content": [
          {
            "type": "paragraph",
            "text": "Thread pools are a way to manage a pool of worker threads that can be reused to execute tasks, reducing the overhead of creating and destroying threads. Task scheduling allows for organizing tasks efficiently."
          },
          {
            "type": "code",
            "language": "python",
            "code": "from concurrent.futures import ThreadPoolExecutor\n\ndef task(n):\n    print(f'Running task {n}')\n\nwith ThreadPoolExecutor(max_workers=5) as executor:\n    executor.map(task, range(10))"
          },
          {
            "type": "paragraph",
            "text": "In this example, a thread pool is created with a maximum of 5 worker threads. The `executor.map` function runs multiple tasks in parallel, reusing threads as needed."
          }
        ]
      },
      {
        "title": "Asynchronous Programming",
        "content": [
          {
            "type": "paragraph",
            "text": "Asynchronous programming allows a program to handle multiple tasks concurrently without using multiple threads or processes. Instead, it uses non-blocking operations and event loops to manage tasks."
          },
          {
            "type": "code",
            "language": "python",
            "code": "import asyncio\n\nasync def async_task(n):\n    print(f'Task {n} started')\n    await asyncio.sleep(1)\n    print(f'Task {n} finished')\n\nasync def main():\n    tasks = [async_task(i) for i in range(5)]\n    await asyncio.gather(*tasks)\n\nasyncio.run(main())"
          },
          {
            "type": "paragraph",
            "text": "Asynchronous functions, defined using `async def`, allow for non-blocking execution. The `await` keyword pauses the function until the awaited operation completes, allowing other tasks to run concurrently."
          }
        ]
      },
      {
        "title": "Conclusion",
        "content": [
          {
            "type": "paragraph",
            "text": "Concurrency is essential for creating efficient and responsive programs. Whether using threads, processes, or asynchronous programming, it is important to handle synchronization, prevent race conditions, and avoid deadlocks to ensure smooth operation."
          }
        ]
      }
    ]
  }  