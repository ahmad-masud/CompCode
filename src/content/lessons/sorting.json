{
    "title": "Sorting Algorithms",
    "lessons": [
      {
        "title": "Introduction to Sorting",
        "content": [
          {
            "type": "paragraph",
            "text": "Sorting algorithms are used to arrange elements of a list or array in a certain order (typically ascending or descending). Sorting is a fundamental operation in computer science and is often a prerequisite for other algorithms like searching, merging, and optimization."
          },
          {
            "type": "bullets",
            "items": [
              "Sorting algorithms differ in terms of time complexity, space complexity, and stability.",
              "Common sorting algorithms include Bubble Sort, Selection Sort, Insertion Sort, Merge Sort, Quick Sort, and Heap Sort.",
              "Choosing the appropriate sorting algorithm depends on the size of the data set, memory constraints, and the required time complexity."
            ]
          }
        ]
      },
      {
        "title": "Bubble Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Bubble Sort is a simple comparison-based sorting algorithm. It repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The process is repeated until the list is sorted."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        swapped = False\n        for j in range(0, n - i - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swapped = True\n        if not swapped:\n            break\n    return arr\n\narr = [64, 34, 25, 12, 22, 11, 90]\nprint(bubble_sort(arr))  # Output: [11, 12, 22, 25, 34, 64, 90]"
          },
          {
            "type": "paragraph",
            "text": "Bubble Sort has a time complexity of O(n^2) in the worst case, making it inefficient for large datasets. However, it is easy to implement and can be useful for small data sets."
          }
        ]
      },
      {
        "title": "Selection Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Selection Sort works by repeatedly selecting the smallest element from the unsorted portion of the list and swapping it with the first unsorted element."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def selection_sort(arr):\n    for i in range(len(arr)):\n        min_index = i\n        for j in range(i + 1, len(arr)):\n            if arr[j] < arr[min_index]:\n                min_index = j\n        arr[i], arr[min_index] = arr[min_index], arr[i]\n    return arr\n\narr = [64, 25, 12, 22, 11]\nprint(selection_sort(arr))  # Output: [11, 12, 22, 25, 64]"
          },
          {
            "type": "paragraph",
            "text": "Selection Sort also has a time complexity of O(n^2), but it performs fewer swaps than Bubble Sort, making it more efficient in terms of memory writes."
          }
        ]
      },
      {
        "title": "Insertion Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Insertion Sort builds the sorted list one element at a time by repeatedly picking the next element and inserting it into the correct position within the sorted portion of the array."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n\narr = [12, 11, 13, 5, 6]\nprint(insertion_sort(arr))  # Output: [5, 6, 11, 12, 13]"
          },
          {
            "type": "paragraph",
            "text": "Insertion Sort has a time complexity of O(n^2) in the worst case, but it performs well for small or nearly sorted datasets with a time complexity of O(n) in the best case."
          }
        ]
      },
      {
        "title": "Merge Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Merge Sort is a divide-and-conquer algorithm that divides the array into two halves, recursively sorts the halves, and then merges the sorted halves to produce the final sorted array."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def merge_sort(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort(left_half)\n        merge_sort(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n    return arr\n\narr = [12, 11, 13, 5, 6, 7]\nprint(merge_sort(arr))  # Output: [5, 6, 7, 11, 12, 13]"
          },
          {
            "type": "paragraph",
            "text": "Merge Sort has a time complexity of O(n log n) and is stable. It requires additional space for the temporary arrays used during merging, making it less space-efficient than some other algorithms."
          }
        ]
      },
      {
        "title": "Quick Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Quick Sort is a divide-and-conquer algorithm that selects a pivot element, partitions the array into two subarrays (one with elements smaller than the pivot and one with elements larger), and recursively sorts the subarrays."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    else:\n        pivot = arr[0]\n        less_than_pivot = [x for x in arr[1:] if x <= pivot]\n        greater_than_pivot = [x for x in arr[1:] if x > pivot]\n        return quick_sort(less_than_pivot) + [pivot] + quick_sort(greater_than_pivot)\n\narr = [10, 7, 8, 9, 1, 5]\nprint(quick_sort(arr))  # Output: [1, 5, 7, 8, 9, 10]"
          },
          {
            "type": "paragraph",
            "text": "Quick Sort has an average-case time complexity of O(n log n), but its worst-case time complexity is O(n^2) when the pivot is poorly chosen. Randomized Quick Sort can help avoid the worst-case scenario."
          }
        ]
      },
      {
        "title": "Heap Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Heap Sort is a comparison-based algorithm that first builds a max heap from the array, then repeatedly extracts the maximum element from the heap and restores the heap structure."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def heapify(arr, n, i):\n    largest = i\n    left = 2 * i + 1\n    right = 2 * i + 2\n\n    if left < n and arr[largest] < arr[left]:\n        largest = left\n\n    if right < n and arr[largest] < arr[right]:\n        largest = right\n\n    if largest != i:\n        arr[i], arr[largest] = arr[largest], arr[i]\n        heapify(arr, n, largest)\n\n\ndef heap_sort(arr):\n    n = len(arr)\n    for i in range(n // 2 - 1, -1, -1):\n        heapify(arr, n, i)\n\n    for i in range(n - 1, 0, -1):\n        arr[i], arr[0] = arr[0], arr[i]\n        heapify(arr, i, 0)\n    return arr\n\narr = [12, 11, 13, 5, 6, 7]\nprint(heap_sort(arr))  # Output: [5, 6, 7, 11, 12, 13]"
          },
          {
            "type": "paragraph",
            "text": "Heap Sort has a time complexity of O(n log n), similar to Merge Sort, but it operates in place, making it more space-efficient. It is not a stable sort."
          }
        ]
      },
      {
        "title": "Counting Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Counting Sort is a non-comparison-based sorting algorithm that works by counting the occurrences of each element in the array, then using those counts to place the elements in the sorted order. It is particularly effective for sorting integers within a known range."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def counting_sort(arr):\n    max_val = max(arr)\n    count = [0] * (max_val + 1)\n    for num in arr:\n        count[num] += 1\n\n    sorted_arr = []\n    for i in range(len(count)):\n        sorted_arr.extend([i] * count[i])\n    return sorted_arr\n\narr = [4, 2, 2, 8, 3, 3, 1]\nprint(counting_sort(arr))  # Output: [1, 2, 2, 3, 3, 4, 8]"
          },
          {
            "type": "paragraph",
            "text": "Counting Sort has a time complexity of O(n + k), where k is the range of the input data. It is very efficient for small ranges of integers but can become impractical for large ranges."
          }
        ]
      },
      {
        "title": "Radix Sort",
        "content": [
          {
            "type": "paragraph",
            "text": "Radix Sort is a non-comparison-based algorithm that sorts numbers by processing individual digits. It repeatedly sorts the numbers by their least significant digit, then by their next least significant digit, until all digits are sorted."
          },
          {
            "type": "code",
            "language": "python",
            "code": "def counting_sort_by_digit(arr, exp):\n    n = len(arr)\n    output = [0] * n\n    count = [0] * 10\n\n    for i in range(n):\n        index = (arr[i] // exp) % 10\n        count[index] += 1\n\n    for i in range(1, 10):\n        count[i] += count[i - 1]\n\n    for i in range(n - 1, -1, -1):\n        index = (arr[i] // exp) % 10\n        output[count[index] - 1] = arr[i]\n        count[index] -= 1\n\n    for i in range(n):\n        arr[i] = output[i]\n\n\ndef radix_sort(arr):\n    max_val = max(arr)\n    exp = 1\n    while max_val // exp > 0:\n        counting_sort_by_digit(arr, exp)\n        exp *= 10\n    return arr\n\narr = [170, 45, 75, 90, 802, 24, 2, 66]\nprint(radix_sort(arr))  # Output: [2, 24, 45, 66, 75, 90, 170, 802]"
          },
          {
            "type": "paragraph",
            "text": "Radix Sort has a time complexity of O(nk), where n is the number of elements and k is the number of digits in the largest number. It is efficient for sorting large numbers or strings of digits."
          }
        ]
      },
      {
        "title": "Conclusion",
        "content": [
          {
            "type": "paragraph",
            "text": "Sorting algorithms are essential for organizing data efficiently. Choosing the right sorting algorithm depends on factors such as time complexity, space complexity, stability, and the size of the dataset. While simple algorithms like Bubble Sort and Insertion Sort are useful for small datasets, more advanced algorithms like Merge Sort, Quick Sort, and Radix Sort are better suited for larger or more complex datasets."
          }
        ]
      }
    ]
  }  